# Customer Support RAG with Sentiment, Escalation & Empathy (Streamlit, 100% Free)

A fully local, free, Streamlit app that:
- Retrieves relevant help articles (RAG using Chroma + Sentence Transformers)
- Detects sentiment & emotion
- Predicts escalation risk (simple, transparent rules)
- Generates empathetic answers (FLAN-T5 small/base â€“ free Hugging Face models)
- Tracks customer satisfaction (SQLite)

---

## ğŸ“œ Features
- **Retrieval-Augmented Generation (RAG)** â€“ searches your help articles and answers using context from relevant documents.
- **Sentiment Analysis** â€“ detects customer mood (positive, neutral, negative).
- **Emotion Detection** â€“ identifies fine-grained emotions like anger, sadness, joy.
- **Escalation Prediction** â€“ flags conversations likely to need human intervention.
- **Empathetic Response Generation** â€“ adapts tone based on customer sentiment & emotion.
- **Customer Satisfaction Feedback** â€“ thumbs up/down stored in SQLite for improvement tracking.
- **Local & Free Models** â€“ no API keys required, runs fully offline after first model download.

---

## Demo Data
A few Markdown help articles are included under `data/sample_kb/articles`. Replace with your own.

## Quickstart

```bash
# 1) Create a virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate   # on Windows: .venv\Scripts\activate

# 2) Install dependencies
pip install -r requirements.txt

# 3) Run the app
streamlit run app.py
```

> The first run will download free Hugging Face models (embeddings, sentiment, emotion, generator).

## Project Structure

```
customer-support-rag-streamlit/
â”œâ”€ app.py                      # Streamlit UI + chat loop
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ data/
â”‚  â””â”€ sample_kb/
â”‚     â””â”€ articles/            # Example Markdown articles
â”œâ”€ src/
â”‚  â”œâ”€ config.py               # Tunables (models, paths, thresholds, etc.)
â”‚  â”œâ”€ data_ingest.py          # Load + chunk articles
â”‚  â”œâ”€ embedder.py             # SentenceTransformers wrapper
â”‚  â”œâ”€ vectorstore.py          # Chroma vector DB helpers
â”‚  â”œâ”€ sentiment.py            # Sentiment + emotion detection
â”‚  â”œâ”€ escalation.py           # Simple escalation scoring
â”‚  â”œâ”€ generator.py            # FLAN-T5 text generation with empathy
â”‚  â”œâ”€ rag_pipeline.py         # Glue: retrieve + generate
â”‚  â””â”€ utils.py                # Misc helpers (prompting, feedback store)
â””â”€ storage/
   â””â”€ chroma/                 # Local Chroma persistence
```

## ğŸš€ How to Use

Once the project is launched (either locally or deployed), follow these steps:

### 1ï¸âƒ£ Select Your Knowledge Base
- Click the **"(Re)Index KB"** button.
  - The system will load and chunk your documents.
  - It will then create **embeddings** and build a **vector database** for quick search.

---

### 2ï¸âƒ£ Ask Questions
- In the **"Customer Support Assistant"** section, type your query in the text box.
- Click **"Ask"**.
- The AI will:
  1. **Analyze** your query (Sentiment + Emotion detection).
  2. **Retrieve** the most relevant context from your KB.
  3. **Generate** a personalized, empathetic answer.

---

### 3ï¸âƒ£ View AIâ€™s Response
- The AIâ€™s generated answer will appear in the **"ğŸ§  AI Answer"** section.
- Below it, you will find:
  - **Sources** used for the answer.
  - **Customer Understanding Metrics**:
    - Sentiment (Positive, Neutral, Negative)
    - Emotion (e.g., Anger, Joy, Sadness)
    - Escalation Risk (if the conversation should be passed to a human agent).

---

### 4ï¸âƒ£ Provide Feedback
- At the bottom of each conversation, you can mark:
  - âœ… **Resolved** â€” if the AIâ€™s answer was helpful.
  - âŒ **Not helpful** â€” if the answer needs improvement.
- Feedback will be stored in the local **SQLite database** (`satisfaction.db`).

---

### 5ï¸âƒ£ Conversation History
- The latest **8 turns** of the conversation are shown.
- Older history is stored in memory for the current session.

---

### ğŸ’¡ Notes
- **All models** used are free and downloaded from Hugging Face on first run.
- You can switch between **generator models** (`t5-small` for speed or `t5-base` for better quality) from the sidebar.
- No internet connection is required after models are downloaded (fully local processing).
